{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" reading configuration from the config file in the workspace (AWS keyID/SecretKey)\"\"\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKIAXQFRFA7IBBC5YANI\n"
     ]
    }
   ],
   "source": [
    "spark\n",
    "print(config['AWS']['AWS_ACCESS_KEY_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://udacity-dend/song_data/A/A/A/*.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[artist_id: string, artist_latitude: double, artist_location: string, artist_longitude: double, artist_name: string, duration: double, num_songs: bigint, song_id: string, title: string, year: bigint]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = \"s3a://udacity-dend/\"\n",
    "song_data = input_data + \"song_data/A/A/A/*.json\"\n",
    "print(song_data)\n",
    "# read song data file\n",
    "df = spark.read.json(song_data)\n",
    "\n",
    "# extract columns to create songs table\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create songs table\n",
    "songs_table =df.select('song_id', 'title', 'year', 'duration', 'artist_id').dropDuplicates()\n",
    "\n",
    "\n",
    "# write songs table to parquet files partitioned by year and artist\n",
    "songs_table.write.partitionBy('year', 'artist_id').parquet(\"songs_table/songs_table.parquet\", \"overwrite\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create artists table()\n",
    "artists_table =  df.select('artist_id', 'artist_name', 'artist_location','artist_latitude','artist_longitude' ).dropDuplicates().withColumnRenamed(\"artist_name\", \"name\").withColumnRenamed(\"artist_location\", \"location\").withColumnRenamed(\"artist_latitude\", \"lattitude\").withColumnRenamed(\"artist_longitude\", \"longitude\")\n",
    "df\n",
    "# write artists table to parquet files\n",
    "artists_table.write.parquet(\"artists_table/artists_table.parquet\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(user_id='26', first_name='Ryan', last_name='Smith', gender='M', level='free')\n"
     ]
    }
   ],
   "source": [
    "# get filepath to log data file\n",
    "input_data = \"s3a://udacity-dend/\"\n",
    "log_data =  input_data + \"log_data/*/*/*.json\"\n",
    "\n",
    "# read log data file\n",
    "df = spark.read.json(log_data)\n",
    "    \n",
    "# filter by actions for song plays\n",
    "df = df.filter(df.page == \"NextSong\")\n",
    "\n",
    "\n",
    "# extract columns for users table    \n",
    "users_table = df.select('userId', 'firstName', 'lastName', 'gender', 'level').withColumnRenamed(\"userId\", \"user_id\").withColumnRenamed(\"firstName\", \"first_name\").withColumnRenamed(\"lastName\", \"last_name\").dropDuplicates()\n",
    "    \n",
    "# wite users table to parquet files\n",
    "users_table.write.parquet(\"users/users.parquet\", \"overwrite\")\n",
    "\n",
    "print(users_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Harmonia', auth='Logged In', firstName='Ryan', gender='M', itemInSession=0, lastName='Smith', length=655.77751, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='Sehr kosmisch', status=200, ts=1542241826796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26', start_time='1.542241826796E9', datetime='1970-01-18 20:24:01.826000')\n"
     ]
    }
   ],
   "source": [
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = udf(lambda x: x/1000)\n",
    "df = df.withColumn('start_time', get_timestamp(df.ts))\n",
    "\n",
    "# create datetime column from original timestamp column\n",
    "get_datetime = udf(lambda x: str(datetime.fromtimestamp(int(x) / 1000)))\n",
    "df = df.withColumn('datetime', get_datetime(df.start_time))\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(datetime='1970-01-18 20:24:27.351000', start_time='1970-01-18 20:24:27.351000', hour=20, day=18, week=3, month=1, year=1970, weekday=1)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import (year, month, dayofmonth, hour,weekofyear, dayofweek)\n",
    "# extract columns to create time table\n",
    "time_table = df.select('datetime').withColumn(\"start_time\", df.datetime).withColumn(\"hour\", hour(df.datetime)).withColumn(\"day\", dayofmonth(df.datetime)).withColumn(\"week\", weekofyear(df.datetime)).withColumn(\"month\", month(df.datetime)).withColumn(\"year\", year(df.datetime)).withColumn(\"weekday\", dayofweek(df.datetime)).dropDuplicates()\n",
    "\n",
    "# write time table to parquet files partitioned by year and month\n",
    "time_table.write.partitionBy('year', 'month').parquet(\"time_table/time_table.parquet\", \"overwrite\")\n",
    "print(time_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist_id='ARSUVLW12454A4C8B8', artist_latitude=35.83073, artist_location='Tennessee', artist_longitude=-85.97874, artist_name='Royal Philharmonic Orchestra/Sir Thomas Beecham', duration=94.56281, num_songs=1, song_id='SOBTCUI12A8AE48B70', title='Faust: Ballet Music (1959 Digital Remaster): VI.     Variations du miroir (Allegretto)', year=0)\n"
     ]
    }
   ],
   "source": [
    "# read in song data to use for songplays table\n",
    "song_df = spark.read.json(input_data + \"song_data/A/A/*/*.json\")\n",
    "\n",
    "print(song_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Elena', auth='Logged In', firstName='Lily', gender='F', itemInSession=5, lastName='Koch', length=269.58322, level='paid', location='Chicago-Naperville-Elgin, IL-IN-WI', method='PUT', page='NextSong', registration=1541048010796.0, sessionId=818, song='Setanta matins', status=200, ts=1542837407796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='15', start_time='1.542837407796E9', datetime='1970-01-18 20:33:57.407000', artist_id='AR5KOSW1187FB35FF4', artist_latitude=49.80388, artist_location='Dubai UAE', artist_longitude=15.47491, artist_name='Elena', duration=269.58322, num_songs=1, song_id='SOZCTXZ12AB0182364', title='Setanta matins', year=0)\n"
     ]
    }
   ],
   "source": [
    "# extract columns from joined song and log datasets to create songplays table \n",
    "songplays_table = df.join(song_df,((song_df.artist_name == df.artist) & (song_df.title == df.song) & (song_df.duration ==df.length)) )\n",
    "print(songplays_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(start_time='1.541440182796E9', user_id='73', level='paid', song_id='SOHDWWH12A6D4F7F6A', artist_id='ARC0IOF1187FB3F6E6', session_id=255, location='Tampa-St. Petersburg-Clearwater, FL', user_agent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.78.2 (KHTML, like Gecko) Version/7.0.6 Safari/537.78.2\"', songplay_id=1)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "songplays_table = songplays_table.select('start_time', 'userId', 'level', 'song_id', 'artist_id', 'sessionId', 'location', 'userAgent').withColumn('songplay_id', monotonically_increasing_id())\\\n",
    ".withColumnRenamed('userId', 'user_id').withColumnRenamed('sessionId', 'session_id').withColumnRenamed('userAgent', 'user_agent').dropDuplicates()\n",
    "\n",
    "print(songplays_table.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write songplays table to parquet files partitioned by year and month\n",
    "songplays_table.write.parquet(\"songplays_table/songplays_table.parquet\", \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
